{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea097d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import mplfinance as mpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400e2bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ngay</th>\n",
       "      <th>Stock</th>\n",
       "      <th>GiaDieuChinh</th>\n",
       "      <th>GiaDongCua</th>\n",
       "      <th>GiaMoCua</th>\n",
       "      <th>GiaCaoNhat</th>\n",
       "      <th>GiaThapNhat</th>\n",
       "      <th>GiaThayDoi</th>\n",
       "      <th>ThayDoiPhanTram</th>\n",
       "      <th>ThayDoi</th>\n",
       "      <th>KhoiLuongKhopLenh</th>\n",
       "      <th>GiaTriKhopLenh</th>\n",
       "      <th>KLThoaThuan</th>\n",
       "      <th>GtThoaThuan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-11-15</th>\n",
       "      <td>15/11/2007</td>\n",
       "      <td>HPG</td>\n",
       "      <td>2.40</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0(0.00 %)</td>\n",
       "      <td>1306330</td>\n",
       "      <td>164000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-11-16</th>\n",
       "      <td>16/11/2007</td>\n",
       "      <td>HPG</td>\n",
       "      <td>2.29</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-4.72</td>\n",
       "      <td>-6(-4.72 %)</td>\n",
       "      <td>248510</td>\n",
       "      <td>30070000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Ngay Stock  GiaDieuChinh  GiaDongCua  GiaMoCua  GiaCaoNhat  \\\n",
       "Date                                                                           \n",
       "2007-11-15  15/11/2007   HPG          2.40       127.0     130.0       130.0   \n",
       "2007-11-16  16/11/2007   HPG          2.29       121.0     121.0       121.0   \n",
       "\n",
       "            GiaThapNhat  GiaThayDoi  ThayDoiPhanTram      ThayDoi  \\\n",
       "Date                                                                \n",
       "2007-11-15        109.0         0.0             0.00    0(0.00 %)   \n",
       "2007-11-16        121.0        -6.0            -4.72  -6(-4.72 %)   \n",
       "\n",
       "            KhoiLuongKhopLenh  GiaTriKhopLenh  KLThoaThuan  GtThoaThuan  \n",
       "Date                                                                     \n",
       "2007-11-15            1306330    164000000000            0            0  \n",
       "2007-11-16             248510     30070000000            0            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('stock/HPG_data.csv')\n",
    "df_raw['Date'] = pd.to_datetime(df_raw['Date'])\n",
    "df_raw = df_raw.sort_values(by='Date')\n",
    "df_raw.set_index('Date', inplace=True)\n",
    "df_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d8d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283ee7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_window(df, target_col, window_size):\n",
    "    df_windows = []\n",
    "    index_list = [] \n",
    "    \n",
    "    for i in range(window_size, len(df)):\n",
    "        features = df.iloc[i - window_size:i].values.flatten()\n",
    "        target = df.iloc[i][target_col]\n",
    "        df_windows.append(np.append(features, target))\n",
    "        \n",
    "        index_list.append(df.index[i])\n",
    "\n",
    "    feature_columns = [f\"{col}_t-{j}\" for j in range(window_size, 0, -1) for col in df.columns]\n",
    "    df_sliding = pd.DataFrame(df_windows, columns=feature_columns + [target_col], index=index_list)\n",
    "\n",
    "    return df_sliding\n",
    "\n",
    "\n",
    "\n",
    "def split_and_scale_data(df, target_col, scaler, window_size, test_size=0.2):\n",
    "    df_sliding = create_sliding_window(df, target_col, window_size)\n",
    "    X = df_sliding.drop(columns=[target_col])\n",
    "    y = df_sliding[target_col]\n",
    "\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    x_scaler = scaler\n",
    "    X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = x_scaler.transform(X_test)\n",
    "\n",
    "    y_scaler = scaler\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "    y_test_scale = y_scaler.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scale, y_train, y_test, x_scaler, y_scaler\n",
    "\n",
    "\n",
    "def evaluate_linear_model(X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, y_train, y_test, y_scaler):\n",
    "    model = LinearRegression().fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    train_pred_scaled = model.predict(X_train_scaled).reshape(-1, 1)\n",
    "    test_pred_scaled = model.predict(X_test_scaled).reshape(-1, 1)\n",
    "\n",
    "    train_pred = y_scaler.inverse_transform(train_pred_scaled).ravel()\n",
    "    test_pred = y_scaler.inverse_transform(test_pred_scaled).ravel()\n",
    "\n",
    "    rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "    mape = lambda y, y_pred: np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "    results = {\n",
    "        'train': {\n",
    "            'MAE': mean_absolute_error(y_train, train_pred),\n",
    "            'RMSE': rmse(y_train, train_pred),\n",
    "            'MAPE': mape(y_train, train_pred)\n",
    "        },\n",
    "        'test': {\n",
    "            'MAE': mean_absolute_error(y_test, test_pred),\n",
    "            'RMSE': rmse(y_test, test_pred),\n",
    "            'MAPE': mape(y_test, test_pred)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return model, results, y_test, test_pred\n",
    "\n",
    "def evaluate_random_forest_model(\n",
    "    X_train_scaled, X_test_scaled,\n",
    "    y_train_scaled, y_test_scaled,\n",
    "    y_train, y_test,\n",
    "    y_scaler,\n",
    "    n_estimators,\n",
    "    max_depth,\n",
    "    min_samples_leaf\n",
    "):\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    train_pred_scaled = model.predict(X_train_scaled).reshape(-1, 1)\n",
    "    test_pred_scaled = model.predict(X_test_scaled).reshape(-1, 1)\n",
    "\n",
    "    train_pred = y_scaler.inverse_transform(train_pred_scaled).ravel()\n",
    "    test_pred = y_scaler.inverse_transform(test_pred_scaled).ravel()\n",
    "\n",
    "    rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "    mape = lambda y, y_pred: np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "    results = {\n",
    "        'train': {\n",
    "            'MAE': mean_absolute_error(y_train, train_pred),\n",
    "            'RMSE': rmse(y_train, train_pred),\n",
    "            'MAPE': mape(y_train, train_pred)\n",
    "        },\n",
    "        'test': {\n",
    "            'MAE': mean_absolute_error(y_test, test_pred),\n",
    "            'RMSE': rmse(y_test, test_pred),\n",
    "            'MAPE': mape(y_test, test_pred)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return model, results, y_test, test_pred\n",
    "\n",
    "\n",
    "def evaluate_XGB_model(\n",
    "    X_train_scaled, X_test_scaled,\n",
    "    y_train_scaled, y_test_scaled,\n",
    "    y_train, y_test,\n",
    "    y_scaler,\n",
    "    max_depth,\n",
    "    reg_lambda,\n",
    "    learning_rate,\n",
    "    n_estimators,\n",
    "    reg_alpha\n",
    "):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        reg_lambda=reg_lambda,\n",
    "        learning_rate=learning_rate,\n",
    "        reg_alpha=reg_alpha,\n",
    "        random_state=42)\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    train_pred_scaled = model.predict(X_train_scaled).reshape(-1, 1)\n",
    "    test_pred_scaled = model.predict(X_test_scaled).reshape(-1, 1)\n",
    "\n",
    "    train_pred = y_scaler.inverse_transform(train_pred_scaled).ravel()\n",
    "    test_pred = y_scaler.inverse_transform(test_pred_scaled).ravel()\n",
    "\n",
    "    rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "    mape = lambda y, y_pred: np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "    results = {\n",
    "        'train': {\n",
    "            'MAE': mean_absolute_error(y_train, train_pred),\n",
    "            'RMSE': rmse(y_train, train_pred),\n",
    "            'MAPE': mape(y_train, train_pred)\n",
    "        },\n",
    "        'test': {\n",
    "            'MAE': mean_absolute_error(y_test, test_pred),\n",
    "            'RMSE': rmse(y_test, test_pred),\n",
    "            'MAPE': mape(y_test, test_pred)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return model, results, y_test, test_pred\n",
    "\n",
    "def run_exp(df_input, ft_cols, target_col, scaler):\n",
    "    list_sliding = [30, 90, 180, 365]\n",
    "\n",
    "    best_linear = {\n",
    "        'window_size': None,\n",
    "        'result': None,\n",
    "        'model': None,\n",
    "        'x_scaler': None,\n",
    "        'y_scaler': None,\n",
    "        'real_target_values': None,\n",
    "        'predicted_values': None\n",
    "    }\n",
    "\n",
    "    list_max_depth = [2, 3, 5, 10]\n",
    "    list_n_estimators = [50, 100, 150, 200]\n",
    "    list_min_samples_leaf = [1, 3, 5, 10]\n",
    "\n",
    "    best_rf = {\n",
    "        'window_size': None,\n",
    "        'result': None,\n",
    "        'model': None,\n",
    "        'x_scaler': None,\n",
    "        'y_scaler': None,\n",
    "        'real_target_values': None,\n",
    "        'predicted_values': None\n",
    "    }\n",
    "\n",
    "    list_max_depth_xgb = [ 6, 7, 8]\n",
    "    list_lambda = [0.5, 1, 2]\n",
    "    list_learning_rate = [0.05, 0.1, 0.5]\n",
    "    list_n_estimators_xgb  = [100, 150, 200]\n",
    "    list_alpha = [0.5, 1]\n",
    "\n",
    "    best_xgb = {\n",
    "        'window_size': None,\n",
    "        'result': None,\n",
    "        'model': None,\n",
    "        'x_scaler': None,\n",
    "        'y_scaler': None,\n",
    "        'real_target_values': None,\n",
    "        'predicted_values': None\n",
    "    }\n",
    "\n",
    "    for t in list_sliding:\n",
    "        print(f\" --------- window size: {t}\")\n",
    "\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scale, y_train, y_test, x_scaler, y_scaler = split_and_scale_data(df_input[ft_cols].copy(), target_col, scaler, t)\n",
    "\n",
    "        model, scores, y_test_inv, test_pred_inv = evaluate_linear_model(X_train_scaled, X_test_scaled, y_train_scaled, y_test_scale, y_train, y_test, y_scaler)\n",
    "\n",
    "        if best_linear['window_size'] is None or scores['test']['RMSE'] < best_linear['result']['test']['RMSE']:\n",
    "            best_linear['window_size'] = t\n",
    "            best_linear['result'] = scores\n",
    "            best_linear['model'] = model\n",
    "            best_linear['x_scaler'] = x_scaler\n",
    "            best_linear['y_scaler'] = y_scaler\n",
    "            best_linear['real_target_values'] = y_test_inv\n",
    "            best_linear['predicted_values'] = test_pred_inv\n",
    "\n",
    "        for n_estimators, max_depth, min_samples_leaf in tqdm(\n",
    "            itertools.product(list_n_estimators, list_max_depth, list_min_samples_leaf),\n",
    "            total=len(list_max_depth) * len(list_n_estimators) * len(list_min_samples_leaf)\n",
    "        ):\n",
    "            model_rf, scores_rf, y_test_inv_rf, test_pred_inv_rf = evaluate_random_forest_model(\n",
    "                X_train_scaled, X_test_scaled,\n",
    "                y_train_scaled, y_test_scale,\n",
    "                y_train, y_test,\n",
    "                y_scaler,\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_leaf=min_samples_leaf\n",
    "            )\n",
    "\n",
    "            if best_rf['window_size'] is None or scores_rf['test']['RMSE'] < best_rf['result']['test']['RMSE']:\n",
    "                best_rf['window_size'] = t\n",
    "                best_rf['result'] = scores_rf\n",
    "                best_rf['model'] = model_rf\n",
    "                best_rf['x_scaler'] = x_scaler\n",
    "                best_rf['y_scaler'] = y_scaler\n",
    "                best_rf['real_target_values'] = y_test_inv_rf\n",
    "                best_rf['predicted_values'] = test_pred_inv_rf\n",
    "\n",
    "        for max_depth, reg_lambda, learning_rate, n_estimators, reg_alpha in tqdm(\n",
    "            itertools.product(list_max_depth_xgb, list_lambda, list_learning_rate, list_n_estimators_xgb, list_alpha),\n",
    "            total=len(list_max_depth_xgb) * len(list_lambda) * len(list_learning_rate) * len(list_n_estimators_xgb) * len(list_alpha)\n",
    "        ):\n",
    "            model_xgb, scores_xgb, y_test_inv_xgb, test_pred_inv_xgb = evaluate_XGB_model(\n",
    "                X_train_scaled, X_test_scaled,\n",
    "                y_train_scaled, y_test_scale,\n",
    "                y_train, y_test,\n",
    "                y_scaler,\n",
    "                max_depth=max_depth,\n",
    "                reg_lambda=reg_lambda,\n",
    "                learning_rate=learning_rate,\n",
    "                n_estimators=n_estimators,\n",
    "                reg_alpha=reg_alpha\n",
    "            )\n",
    "\n",
    "            if best_xgb['window_size'] is None or scores_xgb['test']['RMSE'] < best_xgb['result']['test']['RMSE']:\n",
    "                best_xgb['window_size'] = t\n",
    "                best_xgb['result'] = scores_xgb\n",
    "                best_xgb['model'] = model_xgb\n",
    "                best_xgb['x_scaler'] = x_scaler\n",
    "                best_xgb['y_scaler'] = y_scaler\n",
    "                best_xgb['real_target_values'] = y_test_inv_xgb\n",
    "                best_xgb['predicted_values'] = test_pred_inv_xgb\n",
    "\n",
    "    if best_linear['result'] is not None:\n",
    "        print(\"Best linear RMSE: \", best_linear['result']['test']['RMSE'])\n",
    "    else:\n",
    "        print(\"Best linear RMSE: None\")\n",
    "\n",
    "    if best_rf['result'] is not None:\n",
    "        print(\"Best random forest RMSE: \", best_rf['result']['test']['RMSE'])\n",
    "    else:\n",
    "        print(\"Best random forest RMSE: None\")\n",
    "\n",
    "    if best_xgb['result'] is not None:\n",
    "        print(\"Best XGB RMSE: \", best_xgb['result']['test']['RMSE'])\n",
    "    else:\n",
    "        print(\"Best XGB RMSE: None\")\n",
    "\n",
    "    return best_linear, best_rf, best_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7114c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_best_model_predictions(model_data, x_label='Ngày', y_label=''):\n",
    "    y_true = model_data['real_target_values']\n",
    "    y_pred = model_data['predicted_values']\n",
    "\n",
    "    y_pred = pd.Series(y_pred, index=y_true.index)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(y_true, label='Thực tế', color='blue')\n",
    "    plt.plot(y_pred, label='Dự đoán', color='red')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb07be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------- window size: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [04:23<00:00,  4.11s/it]\n",
      "100%|██████████| 162/162 [00:49<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------- window size: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [13:08<00:00, 12.33s/it]\n",
      "100%|██████████| 162/162 [02:32<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------- window size: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [25:59<00:00, 24.37s/it]\n",
      "100%|██████████| 162/162 [05:30<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------- window size: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [50:41<00:00, 47.52s/it] \n",
      " 70%|██████▉   | 113/162 [06:57<05:04,  6.21s/it]"
     ]
    }
   ],
   "source": [
    "best_linear, best_rf, best_xgb = run_exp(df_raw, ['GiaDongCua', 'ThayDoiPhanTram'], 'GiaDongCua', StandardScaler())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
