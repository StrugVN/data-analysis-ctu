{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17febfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c1e282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_spent_Alone</th>\n",
       "      <th>Stage_fear</th>\n",
       "      <th>Social_event_attendance</th>\n",
       "      <th>Going_outside</th>\n",
       "      <th>Drained_after_socializing</th>\n",
       "      <th>Friends_circle_size</th>\n",
       "      <th>Post_frequency</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>No</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
       "0                  4.0         No                      4.0            6.0   \n",
       "1                  9.0        Yes                      0.0            0.0   \n",
       "2                  9.0        Yes                      1.0            2.0   \n",
       "3                  0.0         No                      6.0            7.0   \n",
       "4                  3.0         No                      9.0            4.0   \n",
       "...                ...        ...                      ...            ...   \n",
       "2895               3.0         No                      7.0            6.0   \n",
       "2896               3.0         No                      8.0            3.0   \n",
       "2897               4.0        Yes                      1.0            1.0   \n",
       "2898              11.0        Yes                      1.0            3.0   \n",
       "2899               3.0         No                      6.0            6.0   \n",
       "\n",
       "     Drained_after_socializing  Friends_circle_size  Post_frequency  \\\n",
       "0                           No                 13.0             5.0   \n",
       "1                          Yes                  0.0             3.0   \n",
       "2                          Yes                  5.0             2.0   \n",
       "3                           No                 14.0             8.0   \n",
       "4                           No                  8.0             5.0   \n",
       "...                        ...                  ...             ...   \n",
       "2895                        No                  6.0             6.0   \n",
       "2896                        No                 14.0             9.0   \n",
       "2897                       Yes                  4.0             0.0   \n",
       "2898                       Yes                  2.0             0.0   \n",
       "2899                        No                  6.0             9.0   \n",
       "\n",
       "     Personality  \n",
       "0      Extrovert  \n",
       "1      Introvert  \n",
       "2      Introvert  \n",
       "3      Extrovert  \n",
       "4      Extrovert  \n",
       "...          ...  \n",
       "2895   Extrovert  \n",
       "2896   Extrovert  \n",
       "2897   Introvert  \n",
       "2898   Introvert  \n",
       "2899   Extrovert  \n",
       "\n",
       "[2900 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('personality_datasert.csv')\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d316cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "missing_value = df_raw.isnull().sum()\n",
    "missing_value = missing_value[missing_value > 0]\n",
    "missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55529eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['Stage_fear'] = df_raw['Stage_fear'].map({'Yes': 1, 'No': 0})\n",
    "df_raw['Drained_after_socializing'] = df_raw['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\n",
    "df_raw['Personality'] = df_raw['Personality'].map({'Introvert': 0, 'Extrovert':1})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ded694f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_spent_Alone</th>\n",
       "      <th>Stage_fear</th>\n",
       "      <th>Social_event_attendance</th>\n",
       "      <th>Going_outside</th>\n",
       "      <th>Drained_after_socializing</th>\n",
       "      <th>Friends_circle_size</th>\n",
       "      <th>Post_frequency</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time_spent_Alone  Stage_fear  Social_event_attendance  Going_outside  \\\n",
       "0               4.0           0                      4.0            6.0   \n",
       "1               9.0           1                      0.0            0.0   \n",
       "\n",
       "   Drained_after_socializing  Friends_circle_size  Post_frequency  Personality  \n",
       "0                          0                 13.0             5.0            1  \n",
       "1                          1                  0.0             3.0            0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d8095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_kfold_pipeline(\n",
    "        df_raw: pd.DataFrame,\n",
    "        ft_cols_qualitative: list[str],\n",
    "        ft_cols_qualitative_to_one_hot: list[str],\n",
    "        ft_cols_quantitative: list[str],\n",
    "        target_col: str,\n",
    "        scaler,\n",
    "        model,\n",
    "        n_splits: int = 5,\n",
    "        random_state: int = 42,\n",
    "        shuffle: bool = True,\n",
    "        scoring=None\n",
    "    ):\n",
    "    \n",
    "    binary_flag_cols = list(set(ft_cols_qualitative) - set(ft_cols_qualitative_to_one_hot))\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\",    scaler,                                   ft_cols_quantitative),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"),   ft_cols_qualitative_to_one_hot),\n",
    "            (\"binary\", \"passthrough\",                            binary_flag_cols)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    X = df_raw.drop(columns=[target_col])\n",
    "    y = df_raw[target_col]\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "    results = cross_validate(pipe, X, y, cv=cv, n_jobs=-1,\n",
    "                             return_train_score=True, scoring=scoring)\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97361522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def run_exp(df_input, ft_cols_qualitative, ft_cols_qualitative_to_one_hot, ft_cols_quantitative, target_col):\n",
    "    df_run = df_input[ft_cols_qualitative + ft_cols_quantitative + [target_col]].copy()\n",
    "\n",
    "    list_max_iter = [10, 20, 30, 40, 50, 100, 200, 300, 500]\n",
    "    list_cs = [1,2,3,4,5,8,10]\n",
    "    best_parameters = {\n",
    "        \"max_iter\": None,\n",
    "        \"cs\": None,\n",
    "        \"test_acc\": -math.inf,\n",
    "        \"cv_scores\": None\n",
    "    }\n",
    "\n",
    "    for max_iter, cs in tqdm(itertools.product(list_max_iter, list_cs), \n",
    "                            total=len(list_max_iter) * len(list_cs), \n",
    "                            desc=\"Running Logistic Regression CV\"):\n",
    "        cv_run = run_kfold_pipeline(\n",
    "            df_raw=df_run,\n",
    "            ft_cols_qualitative=ft_cols_qualitative,\n",
    "            ft_cols_qualitative_to_one_hot=ft_cols_qualitative_to_one_hot,\n",
    "            ft_cols_quantitative=ft_cols_quantitative,\n",
    "            target_col=target_col,\n",
    "            scaler=StandardScaler(),\n",
    "            model=LogisticRegressionCV(\n",
    "                max_iter=max_iter,\n",
    "                Cs=cs,\n",
    "            ),\n",
    "            scoring = {\n",
    "                \"acc\": \"accuracy\",\n",
    "                \"recall\": \"recall\",\n",
    "                \"precision\": \"precision\",\n",
    "                \"f1\": \"f1\",\n",
    "                \"roc_auc\": \"roc_auc\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        mean_test_acc = cv_run[\"test_acc\"].mean()\n",
    "        \n",
    "        if mean_test_acc > best_parameters[\"test_acc\"]:\n",
    "            best_parameters[\"max_iter\"] = max_iter\n",
    "            best_parameters[\"cs\"] = cs\n",
    "            best_parameters[\"test_acc\"] = mean_test_acc\n",
    "            best_parameters[\"cv_scores\"] = cv_run\n",
    "\n",
    "    print(f\"Best parameters LogClass: {best_parameters}\")\n",
    "    cv_scores_logistic = best_parameters[\"cv_scores\"]\n",
    "\n",
    "    list_max_depth = [2, 3, 5, 10]\n",
    "    list_n_estimators = [50, 100, 150, 200]\n",
    "    list_min_samples_leaf = [3, 5, 10, 20]\n",
    "\n",
    "    best_parameters = {\n",
    "        \"max_depth\": None,\n",
    "        \"n_estimators\": None,\n",
    "        \"min_samples_leaf\": None,\n",
    "        \"test_acc\": -math.inf,\n",
    "        \"cv_scores\": None\n",
    "    }\n",
    "\n",
    "    for max_depth, n_estimators, min_samples_leaf in tqdm(\n",
    "        itertools.product(list_max_depth, list_n_estimators, list_min_samples_leaf),\n",
    "        total=len(list_max_depth) * len(list_n_estimators) * len(list_min_samples_leaf)\n",
    "    ):    \n",
    "        cv_run = run_kfold_pipeline(\n",
    "            df_raw=df_run,\n",
    "            ft_cols_qualitative=ft_cols_qualitative,\n",
    "            ft_cols_qualitative_to_one_hot=ft_cols_qualitative_to_one_hot,\n",
    "            ft_cols_quantitative=ft_cols_quantitative,\n",
    "            target_col=target_col,\n",
    "            scaler=StandardScaler(),\n",
    "            model=RandomForestClassifier(\n",
    "                max_depth=max_depth,\n",
    "                n_estimators=n_estimators,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "            ),\n",
    "            scoring = {\n",
    "                \"acc\": \"accuracy\",\n",
    "                \"recall\": \"recall\",\n",
    "                \"precision\": \"precision\",\n",
    "                \"f1\": \"f1\",\n",
    "                \"roc_auc\": \"roc_auc\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        mean_test_acc = cv_run['test_acc'].mean()\n",
    "        if mean_test_acc > best_parameters[\"test_acc\"]:\n",
    "            best_parameters[\"max_depth\"] = max_depth\n",
    "            best_parameters[\"n_estimators\"] = n_estimators\n",
    "            best_parameters[\"min_samples_leaf\"] = min_samples_leaf\n",
    "            best_parameters[\"test_acc\"] = mean_test_acc\n",
    "            best_parameters[\"cv_scores\"] = cv_run\n",
    "\n",
    "    print(f\"Best parameters: {best_parameters}\")\n",
    "\n",
    "    cv_scores_rf = best_parameters[\"cv_scores\"]\n",
    "\n",
    "    list_max_depth = [ 6, 7, 8, 9]\n",
    "    list_lambda = [0.5, 1, 2]\n",
    "    list_learning_rate = [1, 0.8, 0.5, 0.25]\n",
    "    list_n_estimators = [50, 100, 150, 200]\n",
    "    list_alpha = [0.5, 1, 2]\n",
    "\n",
    "    best_parameters = {\n",
    "        \"max_depth\": None,\n",
    "        \"n_estimators\": None,\n",
    "        \"reg_lambda\": None,\n",
    "        \"reg_aplha\": None,\n",
    "        \"learning_rate\": None,\n",
    "        \"test_acc\": -math.inf,\n",
    "        \"cv_scores\": None\n",
    "    }\n",
    "\n",
    "    for max_depth, n_estimators, reg_lambda, lr, alpha in tqdm(\n",
    "        itertools.product(list_max_depth, list_n_estimators, list_lambda, list_learning_rate, list_alpha),\n",
    "        total=len(list_max_depth) * len(list_n_estimators) * len(list_lambda) * len(list_learning_rate) * len(list_alpha)\n",
    "    ):\n",
    "        cv_run = run_kfold_pipeline(\n",
    "            df_raw=df_run,\n",
    "            ft_cols_qualitative=ft_cols_qualitative,\n",
    "            ft_cols_qualitative_to_one_hot=ft_cols_qualitative_to_one_hot,\n",
    "            ft_cols_quantitative=ft_cols_quantitative,\n",
    "            target_col=target_col,\n",
    "            scaler=StandardScaler(),\n",
    "            model=XGBClassifier(\n",
    "                max_depth=max_depth,\n",
    "                n_estimators=n_estimators,\n",
    "                reg_lambda=reg_lambda,\n",
    "                learning_rate=lr,\n",
    "                reg_alpha=alpha,\n",
    "            ),\n",
    "            scoring = {\n",
    "                \"acc\": \"accuracy\",\n",
    "                \"recall\": \"recall\",\n",
    "                \"precision\": \"precision\",\n",
    "                \"f1\": \"f1\",\n",
    "                \"roc_auc\": \"roc_auc\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        mean_test_acc = cv_run['test_acc'].mean()\n",
    "        if mean_test_acc > best_parameters[\"test_acc\"]:\n",
    "            best_parameters[\"max_depth\"] = max_depth\n",
    "            best_parameters[\"n_estimators\"] = n_estimators\n",
    "            best_parameters[\"reg_lambda\"] = reg_lambda\n",
    "            best_parameters[\"reg_aplha\"] = alpha\n",
    "            best_parameters[\"learning_rate\"] = lr\n",
    "            best_parameters[\"test_acc\"] = mean_test_acc\n",
    "            best_parameters[\"cv_scores\"] = cv_run\n",
    "            \n",
    "    print(f\"Best parameters XGB: {best_parameters}\")\n",
    "\n",
    "    cv_scores_xgbc = best_parameters[\"cv_scores\"]\n",
    "\n",
    "    comparison_df = pd.DataFrame({\n",
    "        \"Model\": [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"],\n",
    "        \"Mean Test Accuracy\": [\n",
    "            cv_scores_logistic[\"test_acc\"].mean(),\n",
    "            cv_scores_rf[\"test_acc\"].mean(),\n",
    "            cv_scores_xgbc[\"test_acc\"].mean()\n",
    "        ],\n",
    "        \"Mean F1\": [\n",
    "            cv_scores_logistic[\"test_f1\"].mean(),\n",
    "            cv_scores_rf[\"test_f1\"].mean(),\n",
    "            cv_scores_xgbc[\"test_f1\"].mean()\n",
    "        ],\n",
    "        \"Mean Recall\": [\n",
    "            cv_scores_logistic[\"test_recall\"].mean(),\n",
    "            cv_scores_rf[\"test_recall\"].mean(),\n",
    "            cv_scores_xgbc[\"test_recall\"].mean()\n",
    "        ],\n",
    "        \"Mean Precision\": [\n",
    "            cv_scores_logistic[\"test_precision\"].mean(),\n",
    "            cv_scores_rf[\"test_precision\"].mean(),\n",
    "            cv_scores_xgbc[\"test_precision\"].mean()\n",
    "        ],\n",
    "        \"Mean ROC AUC\": [\n",
    "            cv_scores_logistic[\"test_roc_auc\"].mean(),\n",
    "            cv_scores_rf[\"test_roc_auc\"].mean(),\n",
    "            cv_scores_xgbc[\"test_roc_auc\"].mean()\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    return comparison_df, cv_scores_logistic, cv_scores_rf, cv_scores_xgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eed65ac8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Stop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Stop'"
     ]
    }
   ],
   "source": [
    "raise KeyError(\"Stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df4d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Logistic Regression CV: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:19<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters LogClass: {'max_iter': 10, 'cs': 1, 'test_acc': np.float64(0.9344827586206896), 'cv_scores': {'fit_time': array([0.02661085, 0.02761102, 0.02928615, 0.02710032, 0.03138924]), 'score_time': array([0.01466274, 0.01569319, 0.0185225 , 0.01269317, 0.01293302]), 'test_acc': array([0.9362069 , 0.92241379, 0.9362069 , 0.92586207, 0.95172414]), 'train_acc': array([0.93405172, 0.9375    , 0.93405172, 0.93663793, 0.93017241]), 'test_recall': array([0.92307692, 0.90939597, 0.91275168, 0.9261745 , 0.95637584]), 'train_recall': array([0.9261745 , 0.92958927, 0.92875105, 0.92539816, 0.91785415]), 'test_precision': array([0.95172414, 0.93771626, 0.96113074, 0.92929293, 0.95      ]), 'train_precision': array([0.94439692, 0.94786325, 0.94217687, 0.95008606, 0.94477998]), 'test_f1': array([0.93718166, 0.92333901, 0.9363167 , 0.92773109, 0.95317726]), 'train_f1': array([0.93519695, 0.93863733, 0.93541579, 0.93757962, 0.93112245]), 'test_roc_auc': array([0.91422773, 0.88958899, 0.91702366, 0.88867866, 0.93888334]), 'train_roc_auc': array([0.90903303, 0.91512193, 0.90825177, 0.91541088, 0.90289109])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:15<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 2, 'n_estimators': 50, 'min_samples_leaf': 3, 'test_acc': np.float64(0.9344827586206896), 'cv_scores': {'fit_time': array([0.05013967, 0.05013967, 0.05014014, 0.05715823, 0.05715823]), 'score_time': array([0.0150373 , 0.01604414, 0.01604509, 0.01758099, 0.01758099]), 'test_acc': array([0.9362069 , 0.92241379, 0.9362069 , 0.92586207, 0.95172414]), 'train_acc': array([0.93405172, 0.9375    , 0.93405172, 0.93663793, 0.93017241]), 'test_recall': array([0.92307692, 0.90939597, 0.91275168, 0.9261745 , 0.95637584]), 'train_recall': array([0.9261745 , 0.92958927, 0.92875105, 0.92539816, 0.91785415]), 'test_precision': array([0.95172414, 0.93771626, 0.96113074, 0.92929293, 0.95      ]), 'train_precision': array([0.94439692, 0.94786325, 0.94217687, 0.95008606, 0.94477998]), 'test_f1': array([0.93718166, 0.92333901, 0.9363167 , 0.92773109, 0.95317726]), 'train_f1': array([0.93519695, 0.93863733, 0.93541579, 0.93757962, 0.93112245]), 'test_roc_auc': array([0.95712874, 0.94573159, 0.96528274, 0.95986839, 0.9684421 ]), 'train_roc_auc': array([0.96363575, 0.96497983, 0.96253991, 0.96542386, 0.96444395])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [01:04<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters XGB: {'max_depth': 6, 'n_estimators': 100, 'reg_lambda': 0.5, 'reg_aplha': 2, 'learning_rate': 0.25, 'test_acc': np.float64(0.9331034482758621), 'cv_scores': {'fit_time': array([0.03658962, 0.02611709, 0.02511716, 0.02511716, 0.03552842]), 'score_time': array([0.01979804, 0.01478386, 0.01478386, 0.01377201, 0.01970291]), 'test_acc': array([0.93965517, 0.92068966, 0.9362069 , 0.92241379, 0.94655172]), 'train_acc': array([0.93534483, 0.93922414, 0.93663793, 0.93836207, 0.93491379]), 'test_recall': array([0.9264214 , 0.90604027, 0.91275168, 0.91946309, 0.95302013]), 'train_recall': array([0.9261745 , 0.9270746 , 0.92875105, 0.92539816, 0.9195306 ]), 'test_precision': array([0.95517241, 0.9375    , 0.96113074, 0.92881356, 0.94352159]), 'train_precision': array([0.94682676, 0.95344828, 0.94700855, 0.95336788, 0.95225694]), 'test_f1': array([0.94057725, 0.92150171, 0.9363167 , 0.92411467, 0.94824708]), 'train_f1': array([0.93638677, 0.9400765 , 0.93779094, 0.93917482, 0.93560768]), 'test_roc_auc': array([0.95833085, 0.94786758, 0.97285092, 0.96467585, 0.96691894]), 'train_roc_auc': array([0.98412511, 0.985089  , 0.98263569, 0.9830139 , 0.98344342])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "      <th>Mean F1</th>\n",
       "      <th>Mean Recall</th>\n",
       "      <th>Mean Precision</th>\n",
       "      <th>Mean ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.934483</td>\n",
       "      <td>0.935549</td>\n",
       "      <td>0.925555</td>\n",
       "      <td>0.945973</td>\n",
       "      <td>0.909680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.934483</td>\n",
       "      <td>0.935549</td>\n",
       "      <td>0.925555</td>\n",
       "      <td>0.945973</td>\n",
       "      <td>0.959291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.933103</td>\n",
       "      <td>0.934151</td>\n",
       "      <td>0.923539</td>\n",
       "      <td>0.945228</td>\n",
       "      <td>0.962129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Mean Test Accuracy   Mean F1  Mean Recall  \\\n",
       "0  Logistic Regression            0.934483  0.935549     0.925555   \n",
       "1        Random Forest            0.934483  0.935549     0.925555   \n",
       "2              XGBoost            0.933103  0.934151     0.923539   \n",
       "\n",
       "   Mean Precision  Mean ROC AUC  \n",
       "0        0.945973      0.909680  \n",
       "1        0.945973      0.959291  \n",
       "2        0.945228      0.962129  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ft_cols_qualitative = [\n",
    "    'Stage_fear',\n",
    "    'Drained_after_socializing',\n",
    "]\n",
    "\n",
    "ft_cols_qualitative_to_one_hot = [\n",
    "    \n",
    "]\n",
    "\n",
    "ft_cols_quantitative = [\n",
    "    'Time_spent_Alone',\n",
    "    'Social_event_attendance',\n",
    "    'Going_outside',\n",
    "    'Friends_circle_size',\n",
    "    'Post_frequency'\n",
    "]\n",
    "\n",
    "target_col = 'Personality' ################\n",
    "\n",
    "comparison_df, cv_scores_logistic, cv_scores_rf, cv_scores_xgbc = run_exp(df_raw, ft_cols_qualitative, ft_cols_qualitative_to_one_hot, ft_cols_quantitative, target_col)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef56c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.934483</td>\n",
       "      <td>0.934483</td>\n",
       "      <td>0.925555</td>\n",
       "      <td>0.925553</td>\n",
       "      <td>0.945973</td>\n",
       "      <td>0.945861</td>\n",
       "      <td>0.935549</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.909680</td>\n",
       "      <td>0.910142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.018584</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.021048</td>\n",
       "      <td>0.005243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.026611</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.930172</td>\n",
       "      <td>0.909396</td>\n",
       "      <td>0.917854</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.942177</td>\n",
       "      <td>0.923339</td>\n",
       "      <td>0.931122</td>\n",
       "      <td>0.888679</td>\n",
       "      <td>0.902891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.031389</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.929589</td>\n",
       "      <td>0.961131</td>\n",
       "      <td>0.950086</td>\n",
       "      <td>0.953177</td>\n",
       "      <td>0.938637</td>\n",
       "      <td>0.938883</td>\n",
       "      <td>0.915411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_acc  train_acc  test_recall  train_recall  \\\n",
       "mean  0.028400    0.014901  0.934483   0.934483     0.925555      0.925553   \n",
       "std   0.001952    0.002374  0.011437   0.002859     0.018584      0.004642   \n",
       "min   0.026611    0.012693  0.922414   0.930172     0.909396      0.917854   \n",
       "max   0.031389    0.018523  0.951724   0.937500     0.956376      0.929589   \n",
       "\n",
       "      test_precision  train_precision   test_f1  train_f1  test_roc_auc  \\\n",
       "mean        0.945973         0.945861  0.935549  0.935590      0.909680   \n",
       "std         0.012504         0.003112  0.011448  0.002889      0.021048   \n",
       "min         0.929293         0.942177  0.923339  0.931122      0.888679   \n",
       "max         0.961131         0.950086  0.953177  0.938637      0.938883   \n",
       "\n",
       "      train_roc_auc  \n",
       "mean       0.910142  \n",
       "std        0.005243  \n",
       "min        0.902891  \n",
       "max        0.915411  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_scores_logistic).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12ec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & train\\_acc & test\\_acc & test\\_recall & test\\_precision & test\\_f1 & test\\_roc\\_auc \\\\\n",
      "\\midrule\n",
      "mean & 0.934483 & 0.934483 & 0.925555 & 0.945973 & 0.935549 & 0.909680 \\\\\n",
      "std & 0.002859 & 0.011437 & 0.018584 & 0.012504 & 0.011448 & 0.021048 \\\\\n",
      "min & 0.930172 & 0.922414 & 0.909396 & 0.929293 & 0.923339 & 0.888679 \\\\\n",
      "max & 0.937500 & 0.951724 & 0.956376 & 0.961131 & 0.953177 & 0.938883 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(cv_scores_logistic).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]][\n",
    "        ['train_acc', 'test_acc', 'test_recall', 'test_precision', 'test_f1', 'test_roc_auc']\n",
    "    ].to_latex().replace('_', '\\\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5553eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & train\\_acc & test\\_acc & test\\_recall & test\\_precision & test\\_f1 & test\\_roc\\_auc \\\\\n",
      "\\midrule\n",
      "mean & 0.934483 & 0.934483 & 0.925555 & 0.945973 & 0.935549 & 0.959291 \\\\\n",
      "std & 0.002859 & 0.011437 & 0.018584 & 0.012504 & 0.011448 & 0.008782 \\\\\n",
      "min & 0.930172 & 0.922414 & 0.909396 & 0.929293 & 0.923339 & 0.945732 \\\\\n",
      "max & 0.937500 & 0.951724 & 0.956376 & 0.961131 & 0.953177 & 0.968442 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(cv_scores_rf).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]][\n",
    "        ['train_acc', 'test_acc', 'test_recall', 'test_precision', 'test_f1', 'test_roc_auc']\n",
    "    ].to_latex().replace('_', '\\\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba73f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & train\\_acc & test\\_acc & test\\_recall & test\\_precision & test\\_f1 & test\\_roc\\_auc \\\\\n",
      "\\midrule\n",
      "mean & 0.936897 & 0.933103 & 0.923539 & 0.945228 & 0.934151 & 0.962129 \\\\\n",
      "std & 0.001869 & 0.011200 & 0.018143 & 0.013075 & 0.011241 & 0.009516 \\\\\n",
      "min & 0.934914 & 0.920690 & 0.906040 & 0.928814 & 0.921502 & 0.947868 \\\\\n",
      "max & 0.939224 & 0.946552 & 0.953020 & 0.961131 & 0.948247 & 0.972851 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(cv_scores_xgbc).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]][\n",
    "        ['train_acc', 'test_acc', 'test_recall', 'test_precision', 'test_f1', 'test_roc_auc']\n",
    "    ].to_latex().replace('_', '\\\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f15225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrr}\n",
      "\\toprule\n",
      " & Model & Mean Test Accuracy & Mean F1 & Mean Recall & Mean Precision & Mean ROC AUC \\\\\n",
      "\\midrule\n",
      "0 & Logistic Regression & 0.934483 & 0.935549 & 0.925555 & 0.945973 & 0.909680 \\\\\n",
      "1 & Random Forest & 0.934483 & 0.935549 & 0.925555 & 0.945973 & 0.959291 \\\\\n",
      "2 & XGBoost & 0.933103 & 0.934151 & 0.923539 & 0.945228 & 0.962129 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(comparison_df.to_latex().replace(\"_\", \"\\\\_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fa5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Logistic Regression CV: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:14<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters LogClass: {'max_iter': 10, 'cs': 1, 'test_acc': np.float64(0.9882758620689653), 'cv_scores': {'fit_time': array([0.01651669, 0.01751685, 0.01651669, 0.01651669, 0.01751685]), 'score_time': array([0.01164699, 0.01264668, 0.01164699, 0.01164699, 0.01164675]), 'test_acc': array([0.9862069 , 0.9862069 , 0.98965517, 0.99310345, 0.9862069 ]), 'train_acc': array([0.9887931 , 0.9887931 , 0.98793103, 0.98706897, 0.9887931 ]), 'test_recall': array([1., 1., 1., 1., 1.]), 'train_recall': array([1., 1., 1., 1., 1.]), 'test_precision': array([0.97231834, 0.97231834, 0.97909408, 0.98601399, 0.97241379]), 'train_precision': array([0.97743056, 0.97743056, 0.97573657, 0.97402597, 0.97741095]), 'test_f1': array([0.98596491, 0.98596491, 0.98943662, 0.99295775, 0.98601399]), 'train_f1': array([0.98858648, 0.98858648, 0.9877193 , 0.98684211, 0.98857645]), 'test_roc_auc': array([0.98547947, 0.98801462, 0.99388234, 0.99122995, 0.98986744]), 'train_roc_auc': array([0.99082372, 0.99012268, 0.98870425, 0.98920279, 0.98978782])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:17<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 2, 'n_estimators': 50, 'min_samples_leaf': 3, 'test_acc': np.float64(0.9882758620689653), 'cv_scores': {'fit_time': array([0.07733774, 0.07298779, 0.07499528, 0.07499528, 0.07733774]), 'score_time': array([0.01801229, 0.02035022, 0.01834273, 0.02527118, 0.01701212]), 'test_acc': array([0.9862069 , 0.9862069 , 0.98965517, 0.99310345, 0.9862069 ]), 'train_acc': array([0.9887931 , 0.9887931 , 0.98793103, 0.98706897, 0.9887931 ]), 'test_recall': array([1., 1., 1., 1., 1.]), 'train_recall': array([1., 1., 1., 1., 1.]), 'test_precision': array([0.97231834, 0.97231834, 0.97909408, 0.98601399, 0.97241379]), 'train_precision': array([0.97743056, 0.97743056, 0.97573657, 0.97402597, 0.97741095]), 'test_f1': array([0.98596491, 0.98596491, 0.98943662, 0.99295775, 0.98601399]), 'train_f1': array([0.98858648, 0.98858648, 0.9877193 , 0.98684211, 0.98857645]), 'test_roc_auc': array([0.9833252 , 0.98586629, 0.98797891, 0.99288995, 0.97922319]), 'train_roc_auc': array([0.99202421, 0.99269103, 0.99173785, 0.99145253, 0.99304324])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [00:46<00:00, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters XGB: {'max_depth': 6, 'n_estimators': 50, 'reg_lambda': 1, 'reg_aplha': 2, 'learning_rate': 1, 'test_acc': np.float64(0.9882758620689653), 'cv_scores': {'fit_time': array([0.02084589, 0.01866984, 0.02092552, 0.0165112 , 0.01994395]), 'score_time': array([0.01961279, 0.01437902, 0.01838422, 0.02061176, 0.01734519]), 'test_acc': array([0.9862069 , 0.9862069 , 0.98965517, 0.99310345, 0.9862069 ]), 'train_acc': array([0.9887931 , 0.9887931 , 0.98793103, 0.98706897, 0.9887931 ]), 'test_recall': array([1., 1., 1., 1., 1.]), 'train_recall': array([1., 1., 1., 1., 1.]), 'test_precision': array([0.97231834, 0.97231834, 0.97909408, 0.98601399, 0.97241379]), 'train_precision': array([0.97743056, 0.97743056, 0.97573657, 0.97402597, 0.97741095]), 'test_f1': array([0.98596491, 0.98596491, 0.98943662, 0.99295775, 0.98601399]), 'train_f1': array([0.98858648, 0.98858648, 0.9877193 , 0.98684211, 0.98857645]), 'test_roc_auc': array([0.98578298, 0.98920482, 0.98982373, 0.99211052, 0.98789209]), 'train_roc_auc': array([0.99698946, 0.99735653, 0.99739744, 0.99635332, 0.99724407])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "      <th>Mean F1</th>\n",
       "      <th>Mean Recall</th>\n",
       "      <th>Mean Precision</th>\n",
       "      <th>Mean ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.988276</td>\n",
       "      <td>0.988068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976432</td>\n",
       "      <td>0.989695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.988276</td>\n",
       "      <td>0.988068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976432</td>\n",
       "      <td>0.985857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.988276</td>\n",
       "      <td>0.988068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976432</td>\n",
       "      <td>0.988963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Mean Test Accuracy   Mean F1  Mean Recall  \\\n",
       "0  Logistic Regression            0.988276  0.988068          1.0   \n",
       "1        Random Forest            0.988276  0.988068          1.0   \n",
       "2              XGBoost            0.988276  0.988068          1.0   \n",
       "\n",
       "   Mean Precision  Mean ROC AUC  \n",
       "0        0.976432      0.989695  \n",
       "1        0.976432      0.985857  \n",
       "2        0.976432      0.988963  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ft_cols_qualitative = [\n",
    "    'Stage_fear',\n",
    "    #'Drained_after_socializing',\n",
    "]\n",
    "\n",
    "ft_cols_qualitative_to_one_hot = [\n",
    "    \n",
    "]\n",
    "\n",
    "ft_cols_quantitative = [\n",
    "    'Time_spent_Alone',\n",
    "    'Social_event_attendance',\n",
    "    'Going_outside',\n",
    "    'Friends_circle_size',\n",
    "    'Post_frequency'\n",
    "]\n",
    "\n",
    "target_col = 'Drained_after_socializing' ################\n",
    "\n",
    "comparison_drain_df, cv_drain_scores_logistic, cv_drain_scores_rf, cv_drain_scores_xgbc = run_exp(df_raw, ft_cols_qualitative, ft_cols_qualitative_to_one_hot, ft_cols_quantitative, target_col)\n",
    "comparison_drain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f2b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & train\\_acc & test\\_acc & test\\_recall & test\\_precision & test\\_f1 & test\\_roc\\_auc \\\\\n",
      "\\midrule\n",
      "mean & 0.988276 & 0.988276 & 1.000000 & 0.976432 & 0.988068 & 0.989695 \\\\\n",
      "std & 0.000771 & 0.003084 & 0.000000 & 0.006101 & 0.003116 & 0.003183 \\\\\n",
      "min & 0.987069 & 0.986207 & 1.000000 & 0.972318 & 0.985965 & 0.985479 \\\\\n",
      "max & 0.988793 & 0.993103 & 1.000000 & 0.986014 & 0.992958 & 0.993882 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(cv_drain_scores_logistic).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]][\n",
    "        ['train_acc', 'test_acc', 'test_recall', 'test_precision', 'test_f1', 'test_roc_auc']\n",
    "    ].to_latex().replace('_', '\\\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & train\\_acc & test\\_acc & test\\_recall & test\\_precision & test\\_f1 & test\\_roc\\_auc \\\\\n",
      "\\midrule\n",
      "mean & 0.988276 & 0.988276 & 1.000000 & 0.976432 & 0.988068 & 0.985857 \\\\\n",
      "std & 0.000771 & 0.003084 & 0.000000 & 0.006101 & 0.003116 & 0.005108 \\\\\n",
      "min & 0.987069 & 0.986207 & 1.000000 & 0.972318 & 0.985965 & 0.979223 \\\\\n",
      "max & 0.988793 & 0.993103 & 1.000000 & 0.986014 & 0.992958 & 0.992890 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(cv_drain_scores_rf).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]][\n",
    "        ['train_acc', 'test_acc', 'test_recall', 'test_precision', 'test_f1', 'test_roc_auc']\n",
    "    ].to_latex().replace('_', '\\\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0cc6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & train\\_acc & test\\_acc & test\\_recall & test\\_precision & test\\_f1 & test\\_roc\\_auc \\\\\n",
      "\\midrule\n",
      "mean & 0.988276 & 0.988276 & 1.000000 & 0.976432 & 0.988068 & 0.988963 \\\\\n",
      "std & 0.000771 & 0.003084 & 0.000000 & 0.006101 & 0.003116 & 0.002343 \\\\\n",
      "min & 0.987069 & 0.986207 & 1.000000 & 0.972318 & 0.985965 & 0.985783 \\\\\n",
      "max & 0.988793 & 0.993103 & 1.000000 & 0.986014 & 0.992958 & 0.992111 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(cv_drain_scores_xgbc).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]][\n",
    "        ['train_acc', 'test_acc', 'test_recall', 'test_precision', 'test_f1', 'test_roc_auc']\n",
    "    ].to_latex().replace('_', '\\\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrr}\n",
      "\\toprule\n",
      " & Model & Mean Test Accuracy & Mean F1 & Mean Recall & Mean Precision & Mean ROC AUC \\\\\n",
      "\\midrule\n",
      "0 & Logistic Regression & 0.988276 & 0.988068 & 1.000000 & 0.976432 & 0.989695 \\\\\n",
      "1 & Random Forest & 0.988276 & 0.988068 & 1.000000 & 0.976432 & 0.985857 \\\\\n",
      "2 & XGBoost & 0.988276 & 0.988068 & 1.000000 & 0.976432 & 0.988963 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(comparison_drain_df.to_latex().replace(\"_\", \"\\\\_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d62a4859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Logistic Regression CV: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:13<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters LogClass: {'max_iter': 10, 'cs': 1, 'test_acc': np.float64(0.9893103448275863), 'cv_scores': {'fit_time': array([0.02945518, 0.02844834, 0.0304637 , 0.02952456, 0.02703142]), 'score_time': array([0.01437616, 0.01437616, 0.01437616, 0.01484656, 0.01437616]), 'test_acc': array([0.9862069 , 0.99310345, 0.99137931, 0.99137931, 0.98448276]), 'train_acc': array([0.99008621, 0.98836207, 0.9887931 , 0.9887931 , 0.99051724]), 'test_recall': array([1., 1., 1., 1., 1.]), 'train_recall': array([1., 1., 1., 1., 1.]), 'test_precision': array([0.97241379, 0.98601399, 0.9825784 , 0.9825784 , 0.96907216]), 'train_precision': array([0.98001738, 0.97662338, 0.97746967, 0.97746967, 0.98086957]), 'test_f1': array([0.98601399, 0.99295775, 0.99121265, 0.99121265, 0.98429319]), 'train_f1': array([0.98990785, 0.98817346, 0.98860649, 0.98860649, 0.99034241]), 'test_roc_auc': array([0.99127755, 0.99244966, 0.9930863 , 0.99200938, 0.9895283 ]), 'train_roc_auc': array([0.99178328, 0.99139171, 0.99128424, 0.99148319, 0.99211536])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:18<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 2, 'n_estimators': 50, 'min_samples_leaf': 3, 'test_acc': np.float64(0.9893103448275863), 'cv_scores': {'fit_time': array([0.07821512, 0.07922673, 0.07373714, 0.06973791, 0.07672   ]), 'score_time': array([0.02203035, 0.02103114, 0.02055907, 0.02055931, 0.02113152]), 'test_acc': array([0.9862069 , 0.99310345, 0.99137931, 0.99137931, 0.98448276]), 'train_acc': array([0.99008621, 0.98836207, 0.9887931 , 0.9887931 , 0.99051724]), 'test_recall': array([1., 1., 1., 1., 1.]), 'train_recall': array([1., 1., 1., 1., 1.]), 'test_precision': array([0.97241379, 0.98601399, 0.9825784 , 0.9825784 , 0.96907216]), 'train_precision': array([0.98001738, 0.97662338, 0.97746967, 0.97746967, 0.98086957]), 'test_f1': array([0.98601399, 0.99295775, 0.99121265, 0.99121265, 0.98429319]), 'train_f1': array([0.98990785, 0.98817346, 0.98860649, 0.98860649, 0.99034241]), 'test_roc_auc': array([0.99089676, 0.99342544, 0.9928721 , 0.99367533, 0.98819554]), 'train_roc_auc': array([0.9944198 , 0.99401038, 0.99344626, 0.99378503, 0.99478163])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [00:55<00:00, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters XGB: {'max_depth': 6, 'n_estimators': 50, 'reg_lambda': 0.5, 'reg_aplha': 2, 'learning_rate': 0.5, 'test_acc': np.float64(0.9886206896551725), 'cv_scores': {'fit_time': array([0.01735973, 0.02027273, 0.0143559 , 0.01926613, 0.02027464]), 'score_time': array([0.01390147, 0.02125001, 0.01489067, 0.01627731, 0.02124047]), 'test_acc': array([0.9862069 , 0.99310345, 0.99137931, 0.99137931, 0.98103448]), 'train_acc': array([0.99008621, 0.98836207, 0.9887931 , 0.9887931 , 0.99051724]), 'test_recall': array([1.       , 1.       , 1.       , 1.       , 0.9929078]), 'train_recall': array([1., 1., 1., 1., 1.]), 'test_precision': array([0.97241379, 0.98601399, 0.9825784 , 0.9825784 , 0.96885813]), 'train_precision': array([0.98001738, 0.97662338, 0.97746967, 0.97746967, 0.98086957]), 'test_f1': array([0.98601399, 0.99295775, 0.99121265, 0.99121265, 0.98073555]), 'train_f1': array([0.98990785, 0.98817346, 0.98860649, 0.98860649, 0.99034241]), 'test_roc_auc': array([0.98893926, 0.99368128, 0.99057547, 0.99037317, 0.98629159]), 'train_roc_auc': array([0.99664987, 0.99683395, 0.99608315, 0.99695034, 0.99713962])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "      <th>Mean F1</th>\n",
       "      <th>Mean Recall</th>\n",
       "      <th>Mean Precision</th>\n",
       "      <th>Mean ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.989310</td>\n",
       "      <td>0.989138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978531</td>\n",
       "      <td>0.991670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.989310</td>\n",
       "      <td>0.989138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978531</td>\n",
       "      <td>0.991813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.988621</td>\n",
       "      <td>0.988427</td>\n",
       "      <td>0.998582</td>\n",
       "      <td>0.978489</td>\n",
       "      <td>0.989972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Mean Test Accuracy   Mean F1  Mean Recall  \\\n",
       "0  Logistic Regression            0.989310  0.989138     1.000000   \n",
       "1        Random Forest            0.989310  0.989138     1.000000   \n",
       "2              XGBoost            0.988621  0.988427     0.998582   \n",
       "\n",
       "   Mean Precision  Mean ROC AUC  \n",
       "0        0.978531      0.991670  \n",
       "1        0.978531      0.991813  \n",
       "2        0.978489      0.989972  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ft_cols_qualitative = [\n",
    "    'Drained_after_socializing',\n",
    "]\n",
    "\n",
    "ft_cols_qualitative_to_one_hot = [\n",
    "    \n",
    "]\n",
    "\n",
    "ft_cols_quantitative = [\n",
    "    'Time_spent_Alone',\n",
    "    'Social_event_attendance',\n",
    "    'Going_outside',\n",
    "    'Friends_circle_size',\n",
    "    'Post_frequency'\n",
    "]\n",
    "\n",
    "target_col = 'Stage_fear' ################\n",
    "\n",
    "comparison_stage_df, cv_scores_stage_logistic, cv_scores_stage_rf, cv_scores_stage_xgbc = run_exp(df_raw, ft_cols_qualitative, ft_cols_qualitative_to_one_hot, ft_cols_quantitative, target_col)\n",
    "comparison_stage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc77b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & train\\_acc & test\\_acc & test\\_recall & test\\_precision & test\\_f1 & test\\_roc\\_auc \\\\\n",
      "\\midrule\n",
      "mean & 0.989310 & 0.989310 & 1.000000 & 0.978531 & 0.989138 & 0.991670 \\\\\n",
      "std & 0.000934 & 0.003738 & 0.000000 & 0.007342 & 0.003756 & 0.001367 \\\\\n",
      "min & 0.988362 & 0.984483 & 1.000000 & 0.969072 & 0.984293 & 0.989528 \\\\\n",
      "max & 0.990517 & 0.993103 & 1.000000 & 0.986014 & 0.992958 & 0.993086 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(cv_scores_stage_logistic).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]][\n",
    "        ['train_acc', 'test_acc', 'test_recall', 'test_precision', 'test_f1', 'test_roc_auc']\n",
    "    ].to_latex().replace('_', '\\\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fa3634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & train\\_acc & test\\_acc & test\\_recall & test\\_precision & test\\_f1 & test\\_roc\\_auc \\\\\n",
      "\\midrule\n",
      "mean & 0.989310 & 0.989310 & 1.000000 & 0.978531 & 0.989138 & 0.991813 \\\\\n",
      "std & 0.000934 & 0.003738 & 0.000000 & 0.007342 & 0.003756 & 0.002298 \\\\\n",
      "min & 0.988362 & 0.984483 & 1.000000 & 0.969072 & 0.984293 & 0.988196 \\\\\n",
      "max & 0.990517 & 0.993103 & 1.000000 & 0.986014 & 0.992958 & 0.993675 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(cv_scores_stage_rf).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]][\n",
    "        ['train_acc', 'test_acc', 'test_recall', 'test_precision', 'test_f1', 'test_roc_auc']\n",
    "    ].to_latex().replace('_', '\\\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a36fecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & train\\_acc & test\\_acc & test\\_recall & test\\_precision & test\\_f1 & test\\_roc\\_auc \\\\\n",
      "\\midrule\n",
      "mean & 0.989310 & 0.988621 & 0.998582 & 0.978489 & 0.988427 & 0.989972 \\\\\n",
      "std & 0.000934 & 0.004967 & 0.003172 & 0.007412 & 0.005026 & 0.002688 \\\\\n",
      "min & 0.988362 & 0.981034 & 0.992908 & 0.968858 & 0.980736 & 0.986292 \\\\\n",
      "max & 0.990517 & 0.993103 & 1.000000 & 0.986014 & 0.992958 & 0.993681 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(cv_scores_stage_xgbc).describe(percentiles=[]).loc[[\"mean\", \"std\", \"min\", \"max\"]][\n",
    "        ['train_acc', 'test_acc', 'test_recall', 'test_precision', 'test_f1', 'test_roc_auc']\n",
    "    ].to_latex().replace('_', '\\\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d850cc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrr}\n",
      "\\toprule\n",
      " & Model & Mean Test Accuracy & Mean F1 & Mean Recall & Mean Precision & Mean ROC AUC \\\\\n",
      "\\midrule\n",
      "0 & Logistic Regression & 0.989310 & 0.989138 & 1.000000 & 0.978531 & 0.991670 \\\\\n",
      "1 & Random Forest & 0.989310 & 0.989138 & 1.000000 & 0.978531 & 0.991813 \\\\\n",
      "2 & XGBoost & 0.988621 & 0.988427 & 0.998582 & 0.978489 & 0.989972 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(comparison_stage_df.to_latex().replace(\"_\", \"\\\\_\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
